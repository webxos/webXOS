<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>WebXOS ANYTHING BETA TEST</title>
  <style>
    :root{--neon:#39ff14;--bg:#0a0a0a;--panel:#111}
    *{box-sizing:border-box;margin:0;padding:0;font-family:Courier,monospace}
    html,body{height:100%}
    body{background:var(--bg);color:var(--neon);overflow:hidden}
    .wrap{display:grid;grid-template-columns:360px 1fr;height:100vh;gap:1px;background:var(--neon)}
    .panel{background:var(--panel);display:flex;flex-direction:column}
    .head{padding:12px;border-bottom:1px solid var(--neon);display:flex;justify-content:space-between;align-items:center}
    .head h1{font-size:1.05rem;text-shadow:0 0 6px var(--neon)}
    .left{padding:12px;display:flex;flex-direction:column;gap:10px}
    .note{font-size:0.9rem;color:#bbb}
    .controls{display:flex;flex-direction:column;gap:8px}
    .btn{padding:10px;border:1px solid var(--neon);background:transparent;color:var(--neon);cursor:pointer;border-radius:6px;text-align:left}
    .btn:hover{background:var(--neon);color:#000}
    .terminal{flex:1;overflow:auto;padding:8px;border:1px solid rgba(57,255,20,0.06);background:rgba(0,0,0,0.15)}
    .line{margin-bottom:8px;display:flex}
    .prompt{color:#8a2be2;margin-right:8px}
    .right{position:relative;display:flex;flex-direction:column}
    canvas#threeCanvas{width:100%;height:100%;display:block;background:#050505}
    .editor{position:absolute;top:16px;right:16px;background:rgba(6,6,6,0.92);padding:12px;border:1px solid var(--neon);border-radius:6px;width:340px;max-height:80vh;overflow:auto}
    .drop{position:absolute;inset:0;display:flex;align-items:center;justify-content:center;border:2px dashed rgba(57,255,20,0.06);pointer-events:none;opacity:0;transition:opacity .18s}
    .drop.active{pointer-events:all;opacity:1;background:rgba(57,255,20,0.02)}
    .small{font-size:0.85rem;color:#bbb}
    @media(max-width:900px){ .wrap{grid-template-columns:1fr;grid-template-rows:auto 1fr} .editor{width:92%;right:4%;top:auto;bottom:16px} }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="panel">
      <div class="head"><h1>webXOS ANYTHING BETA TEST</h1><div class="small">Inline canvas renderer (no external Three)</div></div>

      <div class="left">
        <div class="note">Upload a JPEG image or MP4 video (first frame) to generate a CAD-style 3D point cloud rendered directly into the canvas. Drag & drop supported. No network required.</div>

        <div class="controls">
          <button id="uploadImageBtn" class="btn">üìÅ Upload JPEG Image</button>
          <button id="uploadVideoBtn" class="btn">üéû Upload MP4 Video</button>
          <button id="recomputeBtn" class="btn">üîÑ Recompute Depth</button>
          <button id="resetBtn" class="btn">üîÅ Reset Scene</button>
        </div>

        <div style="display:flex;gap:8px;align-items:center;margin-top:8px">
          <div class="small">Export scene:</div>
          <button id="exportBtn" class="btn" style="flex:1">Export JSON</button>
        </div>

        <div class="terminal" id="terminal" aria-live="polite"></div>

        <div class="small" style="margin-top:6px">Supported: JPEG only; MP4 only (first frame). This uses an inline renderer that mimics Three.js visuals without external libs.</div>
      </div>

    </div>

    <div class="panel right">
      <canvas id="threeCanvas" title="3D Scene Canvas"></canvas>

      <div class="editor" id="editor">
        <div style="font-weight:600;margin-bottom:8px">DA3 EDITOR</div>

        <div style="margin-bottom:8px">
          <label class="small">Point size</label><br/>
          <input id="pointSize" type="range" min="0.5" max="6" step="0.1" value="2" style="width:100%"/>
        </div>

        <div style="margin-bottom:8px">
          <label class="small">Depth scale</label><br/>
          <input id="depthScale" type="range" min="0" max="40" step="0.5" value="12" style="width:100%"/>
        </div>

        <div style="margin-bottom:8px">
          <label class="small">Auto-rotate</label><input id="autoRotate" type="checkbox" checked style="margin-left:8px"/>
        </div>

        <div style="margin-top:6px" class="small">Drag & drop JPEG/MP4 onto the canvas to generate the point cloud.</div>

        <div style="margin-top:10px;"><strong class="small">Scene Objects</strong></div>
        <div id="objectList" style="margin-top:6px"></div>
      </div>

      <div class="drop" id="dropZone"><div class="small">Drop JPEG or MP4 here</div></div>
    </div>
  </div>

  <script>
  (function(){

    // Programmatic file inputs
    const imageInput = document.createElement('input'); imageInput.type='file'; imageInput.accept='image/jpeg,image/jpg'; imageInput.style.display='none'; document.body.appendChild(imageInput);
    const videoInput = document.createElement('input'); videoInput.type='file'; videoInput.accept='video/mp4'; videoInput.style.display='none'; document.body.appendChild(videoInput);

    // UI refs
    const uploadImageBtn = document.getElementById('uploadImageBtn');
    const uploadVideoBtn = document.getElementById('uploadVideoBtn');
    const recomputeBtn = document.getElementById('recomputeBtn');
    const resetBtn = document.getElementById('resetBtn');
    const exportBtn = document.getElementById('exportBtn');
    const terminal = document.getElementById('terminal');
    const dropZone = document.getElementById('dropZone');
    const canvas = document.getElementById('threeCanvas');
    const ctx = canvas.getContext('2d');
    const pointSizeEl = document.getElementById('pointSize');
    const depthScaleEl = document.getElementById('depthScale');
    const autoRotateEl = document.getElementById('autoRotate');
    const objectListEl = document.getElementById('objectList');

    function log(msg, level){
      const row = document.createElement('div'); row.className='line';
      const p = document.createElement('span'); p.className='prompt'; p.textContent='webxos:~$';
      const t = document.createElement('span'); t.textContent=' ' + msg;
      if (level === 'error') t.style.color = '#ff6666';
      if (level === 'success') t.style.color = '#7fffb1';
      row.appendChild(p); row.appendChild(t); terminal.appendChild(row); terminal.scrollTop = terminal.scrollHeight;
    }

    // Scene data (inline renderer representation)
    let sceneState = {
      sourceImage: null, // Keep source image for recomputing depth
      points: null, // { positions: Float32Array, colors: Float32Array, count }
      rotation: 0,
      lastTime: 0
    };

    // Resize canvas to fill container
    function resizeCanvas(){
      canvas.width = canvas.clientWidth * devicePixelRatio;
      canvas.height = canvas.clientHeight * devicePixelRatio;
      ctx.setTransform(devicePixelRatio, 0, 0, devicePixelRatio, 0, 0);
      render();
    }
    window.addEventListener('resize', resizeCanvas);

    // Simple "3D-like" renderer:
    // - draws point cloud by projecting 3D positions onto 2D screen using a simple camera transform and perspective
    // - supports rotation around Y axis (auto-rotate)
    function render(time){
      if (!time) time = performance.now();
      const dt = (time - (sceneState.lastTime || time)) / 1000;
      sceneState.lastTime = time;
      if (autoRotateEl.checked) sceneState.rotation += dt * 0.25;

      // clear
      ctx.clearRect(0,0,canvas.width,canvas.height);

      const w = canvas.clientWidth;
      const h = canvas.clientHeight;

      // Dark gradient background
      const g = ctx.createLinearGradient(0,0,0,h);
      g.addColorStop(0, '#071022');
      g.addColorStop(1, '#050505');
      ctx.fillStyle = g; ctx.fillRect(0,0,w,h);

      // Draw coordinate grid
      drawCoordinateGrid(w, h);

      // draw point cloud with simple perspective
      if (sceneState.points && sceneState.points.count > 0){
        const pts = sceneState.points;
        // simple camera parameters
        const cam = {
          fov: 65 * Math.PI/180,
          aspect: w / h,
          near: 0.1,
          far: 1000,
          z: 30
        };
        const f = 1 / Math.tan(cam.fov / 2);
        const cx = w/2, cy = h/2;
        const rot = sceneState.rotation;
        const cosR = Math.cos(rot), sinR = Math.sin(rot);
        const psize = parseFloat(pointSizeEl.value);

        // draw farther points first (painter's)
        const projected = [];
        for (let i=0;i<pts.count;i++){
          const xi = pts.positions[i*3 + 0];
          const yi = pts.positions[i*3 + 1];
          const zi = pts.positions[i*3 + 2];
          // rotate around Y
          const rx = xi * cosR - zi * sinR;
          const rz = xi * sinR + zi * cosR;
          const ry = yi;
          // camera at (0,0,cam.z) looking at origin
          const dz = cam.z - rz;
          const depthScale = parseFloat(depthScaleEl.value) || 12;
          const zcam = dz / (depthScale / 12);
          const clip = zcam > 0.1;
          if (!clip) continue;
          // perspective projection
          const px = (rx / zcam) * (f * cam.aspect) * cx + cx;
          const py = (ry / zcam) * f * cy + cy;
          projected.push({ px, py, zcam, r: pts.colors[i*3], g: pts.colors[i*3+1], b: pts.colors[i*3+2] });
        }
        projected.sort((a,b)=> b.zcam - a.zcam);
        // draw points
        for (let p of projected){
          ctx.beginPath();
          const size = Math.max(0.5, psize * (12 / Math.max(4, p.zcam)));
          ctx.fillStyle = `rgba(${Math.round(p.r*255)},${Math.round(p.g*255)},${Math.round(p.b*255)},0.95)`;
          ctx.arc(p.px, p.py, size, 0, Math.PI*2);
          ctx.fill();
        }
      }

      requestAnimationFrame(render);
    }

    // Draw coordinate grid centered at origin
    function drawCoordinateGrid(w, h){
      const cam = { z: 30 };
      const f = 1 / Math.tan(65 * Math.PI/180 / 2);
      const cx = w/2, cy = h/2;
      const aspect = w / h;
      const rot = sceneState.rotation;
      const cosR = Math.cos(rot), sinR = Math.sin(rot);
      
      ctx.strokeStyle = 'rgba(57,255,20,0.2)';
      ctx.lineWidth = 1;
      
      // Grid lines
      for (let i = -10; i <= 10; i++) {
        if (i === 0) continue; // Skip center lines (they'll be drawn separately)
        
        // X-axis lines (parallel to X, varying Z)
        const x1 = i, z1 = -10, x2 = i, z2 = 10;
        const rx1 = x1 * cosR - z1 * sinR;
        const rz1 = x1 * sinR + z1 * cosR;
        const rx2 = x2 * cosR - z2 * sinR;
        const rz2 = x2 * sinR + z2 * cosR;
        
        const dz1 = cam.z - rz1;
        const dz2 = cam.z - rz2;
        const zcam1 = dz1 / 1;
        const zcam2 = dz2 / 1;
        
        if (zcam1 > 0.1 && zcam2 > 0.1) {
          const px1 = (rx1 / zcam1) * (f * aspect) * cx + cx;
          const py1 = (0 / zcam1) * f * cy + cy;
          const px2 = (rx2 / zcam2) * (f * aspect) * cx + cx;
          const py2 = (0 / zcam2) * f * cy + cy;
          
          ctx.beginPath();
          ctx.moveTo(px1, py1);
          ctx.lineTo(px2, py2);
          ctx.stroke();
        }
        
        // Z-axis lines (parallel to Z, varying X)
        const x3 = -10, z3 = i, x4 = 10, z4 = i;
        const rx3 = x3 * cosR - z3 * sinR;
        const rz3 = x3 * sinR + z3 * cosR;
        const rx4 = x4 * cosR - z4 * sinR;
        const rz4 = x4 * sinR + z4 * cosR;
        
        const dz3 = cam.z - rz3;
        const dz4 = cam.z - rz4;
        const zcam3 = dz3 / 1;
        const zcam4 = dz4 / 1;
        
        if (zcam3 > 0.1 && zcam4 > 0.1) {
          const px3 = (rx3 / zcam3) * (f * aspect) * cx + cx;
          const py3 = (0 / zcam3) * f * cy + cy;
          const px4 = (rx4 / zcam4) * (f * aspect) * cx + cx;
          const py4 = (0 / zcam4) * f * cy + cy;
          
          ctx.beginPath();
          ctx.moveTo(px3, py3);
          ctx.lineTo(px4, py4);
          ctx.stroke();
        }
      }
      
      // Center axes (X and Z)
      ctx.strokeStyle = 'rgba(57,255,20,0.6)';
      ctx.lineWidth = 2;
      
      // X-axis (red)
      const xStart = -10 * cosR - 0 * sinR;
      const zStart = -10 * sinR + 0 * cosR;
      const xEnd = 10 * cosR - 0 * sinR;
      const zEnd = 10 * sinR + 0 * cosR;
      
      const dzStart = cam.z - zStart;
      const dzEnd = cam.z - zEnd;
      const zcamStart = dzStart / 1;
      const zcamEnd = dzEnd / 1;
      
      if (zcamStart > 0.1 && zcamEnd > 0.1) {
        const pxStart = (xStart / zcamStart) * (f * aspect) * cx + cx;
        const pyStart = (0 / zcamStart) * f * cy + cy;
        const pxEnd = (xEnd / zcamEnd) * (f * aspect) * cx + cx;
        const pyEnd = (0 / zcamEnd) * f * cy + cy;
        
        ctx.beginPath();
        ctx.moveTo(pxStart, pyStart);
        ctx.lineTo(pxEnd, pyEnd);
        ctx.strokeStyle = 'rgba(255,50,50,0.8)';
        ctx.stroke();
      }
      
      // Z-axis (blue)
      const zStart2 = 0 * cosR - (-10) * sinR;
      const zzStart2 = 0 * sinR + (-10) * cosR;
      const zEnd2 = 0 * cosR - 10 * sinR;
      const zzEnd2 = 0 * sinR + 10 * cosR;
      
      const dzStart2 = cam.z - zzStart2;
      const dzEnd2 = cam.z - zzEnd2;
      const zcamStart2 = dzStart2 / 1;
      const zcamEnd2 = dzEnd2 / 1;
      
      if (zcamStart2 > 0.1 && zcamEnd2 > 0.1) {
        const pxStart2 = (zStart2 / zcamStart2) * (f * aspect) * cx + cx;
        const pyStart2 = (0 / zcamStart2) * f * cy + cy;
        const pxEnd2 = (zEnd2 / zcamEnd2) * (f * aspect) * cx + cx;
        const pyEnd2 = (0 / zcamEnd2) * f * cy + cy;
        
        ctx.beginPath();
        ctx.moveTo(pxStart2, pyStart2);
        ctx.lineTo(pxEnd2, pyEnd2);
        ctx.strokeStyle = 'rgba(50,100,255,0.8)';
        ctx.stroke();
      }
    }

    // Depth estimator (brightness + radial center bias), returns depth array and builds 3D point positions
    function estimateDepthAndPoints(image, options = {}){
      const maxDim = 700;
      let w = image.naturalWidth || image.width, h = image.naturalHeight || image.height;
      const scale = Math.min(1, maxDim / Math.max(w,h));
      w = Math.max(1, Math.floor(w * scale)); h = Math.max(1, Math.floor(h * scale));
      const c = document.createElement('canvas'); c.width = w; c.height = h;
      const gctx = c.getContext('2d'); gctx.drawImage(image, 0, 0, w, h);
      const data = gctx.getImageData(0,0,w,h).data;
      const depth = new Float32Array(w*h);
      for (let y=0;y<h;y++){
        for (let x=0;x<w;x++){
          const i = (y*w + x)*4;
          const r = data[i]/255, g = data[i+1]/255, b = data[i+2]/255;
          const bright = 0.2126*r + 0.7152*g + 0.0722*b;
          const cx = (x/w - 0.5)*2, cy = (y/h - 0.5)*2;
          const radial = Math.exp(-(cx*cx + cy*cy) * 0.9);
          depth[y*w + x] = bright * 0.9 + radial * 0.5;
        }
      }
      // normalize
      let min = Infinity, max = -Infinity;
      for (let i=0;i<depth.length;i++){ if (depth[i]<min) min=depth[i]; if (depth[i]>max) max=depth[i]; }
      const range = (max - min) || 1;
      for (let i=0;i<depth.length;i++) depth[i] = (depth[i] - min) / range;

      // build positions and colors, sample with step
      const maxPoints = 12000;
      const step = Math.max(1, Math.floor(Math.sqrt((w*h)/maxPoints)));
      const positions = [];
      const colors = [];
      for (let y=0;y<h;y+=step){
        for (let x=0;x<w;x+=step){
          const idx = y*w + x;
          const px = idx*4;
          const r = data[px]/255, g = data[px+1]/255, b = data[px+2]/255;
          const d = depth[idx];
          // map to 3D space: X right, Y up, Z forward - centered at (0,0,0)
          const X = (x / w - 0.5) * 16;
          const Y = (0.5 - y / h) * 9;
          const Z = (d - 0.5) * (parseFloat(depthScaleEl.value) || 12);
          positions.push(X, Y, Z);
          colors.push(r, g, b);
        }
      }
      return { positions: new Float32Array(positions), colors: new Float32Array(colors), count: positions.length / 3 };
    }

    // Create point cloud and store in sceneState
    function createPointCloudFromImage(image){
      log('Image uploaded: running DA3 brightness depth', 'info');
      const p = estimateDepthAndPoints(image);
      sceneState.points = p;
      sceneState.sourceImage = image;
      refreshObjectList();
      log('DA3 point cloud created and placed at 0,0,0 (' + p.count + ' points)', 'success');
    }

    // Recompute depth with current settings
    function recomputeDepth(){
      if (!sceneState.sourceImage) {
        log('No source image available to recompute depth', 'error');
        return;
      }
      log('Recomputing depth with current scale...', 'info');
      const p = estimateDepthAndPoints(sceneState.sourceImage);
      sceneState.points = p;
      log('Depth recomputed (' + p.count + ' points)', 'success');
    }

    function clearScene(){
      sceneState.sourceImage = null; 
      sceneState.points = null; 
      sceneState.rotation = 0;
      refreshObjectList();
      log('Scene cleared', 'info');
    }

    function refreshObjectList(){
      objectListEl.innerHTML = '';
      const list = [];
      if (sceneState.points) list.push('Point Cloud (' + sceneState.points.count + ' points)');
      if (list.length === 0) {
        const el = document.createElement('div'); 
        el.textContent = 'No objects'; 
        el.style.padding='6px'; 
        el.style.border='1px solid rgba(57,255,20,0.04)';
        objectListEl.appendChild(el);
      } else {
        list.forEach(n=>{
          const el = document.createElement('div'); 
          el.textContent = n; 
          el.style.padding='6px'; 
          el.style.border='1px solid rgba(57,255,20,0.04)';
          objectListEl.appendChild(el);
        });
      }
    }

    // Extract first frame from MP4 file
    function extractFirstFrameFromVideo(file){
      return new Promise((resolve,reject)=>{
        const url = URL.createObjectURL(file);
        const v = document.createElement('video');
        v.muted = true; v.crossOrigin = 'anonymous'; v.preload = 'auto'; v.src = url;
        let done = false;
        const timeout = setTimeout(()=> {
          if (!done) { URL.revokeObjectURL(url); reject(new Error('Video load timeout')); }
        }, 10000);
        v.addEventListener('loadeddata', ()=>{
          try { v.currentTime = 0.02; } catch(e){ /* ignore */ }
        });
        v.addEventListener('seeked', ()=>{
          if (done) return;
          const c = document.createElement('canvas'); c.width = v.videoWidth; c.height = v.videoHeight;
          const g = c.getContext('2d'); g.drawImage(v,0,0,c.width,c.height);
          const img = new Image();
          img.onload = ()=> { done = true; clearTimeout(timeout); URL.revokeObjectURL(url); resolve(img); };
          img.onerror = ()=> { done = true; clearTimeout(timeout); URL.revokeObjectURL(url); reject(new Error('Frame capture failed')); };
          img.src = c.toDataURL('image/jpeg');
        });
        v.addEventListener('error', ()=> { clearTimeout(timeout); URL.revokeObjectURL(url); reject(new Error('Video load error')); });
      });
    }

    // File handling
    function handleImageFile(file){
      if (!file) return log('No file', 'error');
      const t = (file.type || '').toLowerCase();
      if (!t.includes('jpeg') && !t.includes('jpg')) return log('Only JPEG supported', 'error');
      const reader = new FileReader();
      reader.onerror = ()=> log('File read error', 'error');
      reader.onload = (ev)=>{
        const img = new Image();
        img.onload = ()=> { createPointCloudFromImage(img); };
        img.onerror = ()=> log('Invalid image', 'error');
        img.src = ev.target.result;
      };
      reader.readAsDataURL(file);
    }

    function handleVideoFile(file){
      if (!file) return log('No file', 'error');
      const t = (file.type || '').toLowerCase();
      if (!t.includes('mp4')) return log('Only MP4 supported', 'error');
      extractFirstFrameFromVideo(file).then(img=>{
        createPointCloudFromImage(img);
      }).catch(err=> log('Video frame error: ' + err.message, 'error'));
    }

    // Drag & drop
    function preventDefaults(e){ e.preventDefault(); e.stopPropagation(); }
    ['dragenter','dragover','dragleave','drop'].forEach(ev => canvas.addEventListener(ev, preventDefaults));
    canvas.addEventListener('dragover', ()=> dropZone.classList.add('active'));
    canvas.addEventListener('dragleave', ()=> dropZone.classList.remove('active'));
    canvas.addEventListener('drop', (e)=>{
      dropZone.classList.remove('active');
      const f = e.dataTransfer && e.dataTransfer.files && e.dataTransfer.files[0];
      if (!f) return log('No file dropped', 'error');
      const t = (f.type || '').toLowerCase();
      if (t.includes('jpeg') || t.includes('jpg')) handleImageFile(f);
      else if (t.includes('mp4')) handleVideoFile(f);
      else log('Unsupported file type. Use JPEG or MP4', 'error');
    });

    // UI wiring
    uploadImageBtn.addEventListener('click', ()=> imageInput.click());
    uploadVideoBtn.addEventListener('click', ()=> videoInput.click());
    recomputeBtn.addEventListener('click', ()=> recomputeDepth());
    resetBtn.addEventListener('click', ()=> clearScene());
    exportBtn.addEventListener('click', ()=>{
      const payload = { 
        points: sceneState.points ? sceneState.points.count : 0, 
        depthScale: depthScaleEl.value,
        pointSize: pointSizeEl.value
      };
      const blob = new Blob([JSON.stringify(payload, null, 2)], { type:'application/json' });
      const a = document.createElement('a'); a.href = URL.createObjectURL(blob); a.download = 'point_cloud.json'; document.body.appendChild(a); a.click(); a.remove();
      log('Point cloud exported', 'success');
    });

    imageInput.addEventListener('change', (e)=> { const f = e.target.files && e.target.files[0]; if (!f) return; handleImageFile(f); imageInput.value=''; });
    videoInput.addEventListener('change', (e)=> { const f = e.target.files && e.target.files[0]; if (!f) return; handleVideoFile(f); videoInput.value=''; });

    pointSizeEl.addEventListener('input', ()=> { /* size applied in render loop */ });
    depthScaleEl.addEventListener('input', ()=> { 
      log('Depth scale changed - use "Recompute Depth" to regenerate point cloud', 'info'); 
    });

    // Initialize canvas size and start renderer
    function start(){
      resizeCanvas();
      requestAnimationFrame(render);
      log('CAD-style point cloud editor ready. Upload JPEG or MP4 (first frame) or drag & drop on the canvas.', 'success');
    }

    start();

  })();
  </script>
</body>
</html>
