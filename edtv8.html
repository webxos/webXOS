<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>EDTV: CHANNEL 8 // 2025 AR MASK DEPLOYMENT</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
<link href="https://fonts.googleapis.com/css2?family=Press+Start+2P&display=swap" rel="stylesheet" />
<style>
  *{margin:0;padding:0;box-sizing:border-box;font-family:'Press Start 2P',cursive;image-rendering:pixelated}
  body{background:#000;color:#0f0;overflow:hidden;height:100dvh;touch-action:manipulation;user-select:none}
  #app{position:relative;width:100%;height:100dvh;display:flex;flex-direction:column}
  .grid,.crt{position:absolute;inset:0;pointer-events:none}
  .grid{background:linear-gradient(rgba(0,255,0,0.06)1px,transparent 1px),linear-gradient(90deg,rgba(0,255,0,0.06)1px,transparent 1px);background-size:12px 12px}
  .crt{background:linear-gradient(transparent 50%,rgba(0,30,0,0.15)50%);background-size:100% 4px;animation:s 8s linear infinite}
  @keyframes s{0%{background-position:0 0}100%{background-position:0 100%}}
  .banner{background:rgba(0,40,0,0.98);border-bottom:2px solid #0f0;padding:12px 8px;font-size:10px;text-align:center;text-shadow:0 0 10px #0f0}
  .content{flex:1;display:flex;flex-direction:column;gap:8px;padding:8px;padding-bottom:max(env(safe-area-inset-bottom),20px)}
  .ar-view{flex:1;position:relative;border:2px solid #0f0;overflow:hidden;background:#000;border-radius:8px;box-shadow:0 0 20px rgba(0,255,0,0.6)}
  #video{width:100%;height:100%;object-fit:cover}
  #canvas{position:absolute;inset:0;width:100%;height:100%}
  .controls{display:flex;flex-wrap:wrap;gap:8px;justify-content:center;padding:10px;background:rgba(0,30,0,0.9);border:2px solid #0f0}
  .btn,.dropdown{font-size:9px;padding:10px 14px;border:2px solid #0f0;background:#000;color:#0f0;cursor:pointer;transition:.2s;flex:1 1 100px;max-width:220px}
  .btn:hover,.btn:active,.dropdown:active{background:#0f0;color:#000;box-shadow:0 0 15px #0f0}
  .terminal{height:16dvh;background:rgba(0,0,0,0.9);border:2px solid #0f0;padding:8px;font-size:8px;overflow-y:auto;color:#0f0}
  .status{position:absolute;bottom:8px;left:8px;right:8px;display:flex;gap:8px;z-index:20;flex-wrap:wrap}
  .ind{padding:4px 8px;font-size:7px;background:rgba(0,60,0,0.9);border:1px solid #0f0;border-radius:4px}
  .locked{background:rgba(0,255,0,0.9);box-shadow:0 0 12px #0f0;animation:p 1.5s infinite}
  @keyframes p{0%,100%{opacity:1}50%{opacity:0.6}}
</style>
</head>
<body>
<div id="app">
  <div class="grid"></div><div class="crt"></div>
  <div class="banner">EDTV: CHANNEL 8 // 2025 AR MASK DEPLOYMENT</div>
  <div class="content">
    <div class="controls">
      <button class="btn" id="start">SYNC / CALIBRATE / DEPLOY</button>
      <button class="btn" id="export">EXPORT FIT JSON</button>
      <select class="dropdown" id="mask-select">
        <option value="oni" selected>ONI DEMON</option>
        <option value="tactical">TACTICAL</option>
        <option value="gas">GAS MASK</option>
        <option value="respirator">RESPIRATOR</option>
        <option value="half">HALF FACE</option>
        <option value="full">FULL HELMET</option>
      </select>
    </div>
    <div class="terminal" id="log">> CHANNEL 8 2025 ONLINE<br>> READY FOR AR DEPLOYMENT</div>
    <div class="ar-view">
      <video id="video" autoplay playsinline muted></video>
      <canvas id="canvas"></canvas>
      <div class="status">
        <div class="ind" id="track">TRACKING: OFF</div>
        <div class="ind" id="mask">MASK: ONI DEMON</div>
      </div>
    </div>
  </div>
</div>

<script type="module">
import * as THREE from 'https://cdn.jsdelivr.net/npm/three@0.170.0/build/three.module.js';
import {GLTFLoader} from 'https://cdn.jsdelivr.net/npm/three@0.170.0/examples/jsm/loaders/GLTFLoader.js';
import {FaceLandmarker, FilesetResolver} from 'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.14/vision_bundle.mjs';

const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
const logEl = document.getElementById('log');
const trackEl = document.getElementById('track');
const maskEl = document.getElementById('mask');

let faceLandmarker, renderer, scene, camera, maskObject = null;
let currentMask = 'oni';
let currentConfig = {};
let running = false;
let rafId = null;

// Warn if not secure (except localhost)
if (location.protocol !== 'https:' && location.hostname !== 'localhost') {
  log('WARNING: Use HTTPS or localhost for camera access.');
}

const maskConfigs = {
  oni:       {baseScale: 1.6, zOffset: -0.55, yOffset: -0.02, xOffset: 0.00},
  tactical:  {baseScale: 1.9, zOffset: -0.50, yOffset:  0.06, xOffset: 0.00},
  gas:       {baseScale: 2.2, zOffset: -0.62, yOffset:  0.02, xOffset: 0.00},
  respirator:{baseScale: 1.3, zOffset: -0.42, yOffset:  0.10, xOffset: 0.00},
  half:      {baseScale: 1.4, zOffset: -0.48, yOffset:  0.05, xOffset: 0.00},
  full:      {baseScale: 1.8, zOffset: -0.52, yOffset:  0.04, xOffset: 0.00}
};

// Replace with actual face mask/helmet GLTFs rigged for frontal alignment
const maskModels = {
  oni:       'https://raw.githubusercontent.com/KhronosGroup/glTF-Sample-Assets/main/Models/FaceMask/glTF/FaceMask.gltf',
  tactical:  'https://raw.githubusercontent.com/mrdoob/three.js/dev/examples/models/gltf/DamagedHelmet/glTF/DamagedHelmet.gltf',
  gas:       'https://raw.githubusercontent.com/KhronosGroup/glTF-Sample-Assets/main/Models/AntiqueCamera/glTF/AntiqueCamera.gltf',
  respirator:'https://raw.githubusercontent.com/KhronosGroup/glTF-Sample-Assets/main/Models/BarramundiFish/glTF/BarramundiFish.gltf',
  half:      'https://raw.githubusercontent.com/mrdoob/three.js/dev/examples/models/gltf/DamagedHelmet/glTF/DamagedHelmet.gltf',
  full:      'https://raw.githubusercontent.com/mrdoob/three.js/dev/examples/models/gltf/DamagedHelmet/glTF/DamagedHelmet.gltf'
};

function log(m) {
  const d = document.createElement('div');
  d.textContent = '> ' + m;
  logEl.appendChild(d);
  logEl.scrollTop = logEl.scrollHeight;
}

function initThree() {
  scene = new THREE.Scene();
  camera = new THREE.PerspectiveCamera(60, 1, 0.1, 10);
  renderer = new THREE.WebGLRenderer({canvas, alpha: true, antialias: true});
  // outputColorSpace is deprecated; defaults are fine
  renderer.toneMapping = THREE.ACESFilmicToneMapping;
  // Let Three.js manage DPR and internal canvas size
  renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));

  const hemi = new THREE.HemisphereLight(0x88ffcc, 0x226644, 1.6);
  const dir = new THREE.DirectionalLight(0x88ff88, 0.6);
  dir.position.set(0.5, 1, 0.8);
  scene.add(hemi, dir);

  resize();
  window.addEventListener('resize', resize);
}

function resize() {
  const w = canvas.clientWidth;
  const h = canvas.clientHeight;
  if (w === 0 || h === 0) return;
  renderer.setSize(w, h); // allow DPR scaling internally
  camera.aspect = w / h;
  camera.updateProjectionMatrix();
}

const gltfLoader = new GLTFLoader();
gltfLoader.crossOrigin = 'anonymous';

function clearMask() {
  if (maskObject) {
    scene.remove(maskObject);
    maskObject.traverse(o => {
      // Dispose geometries, materials, textures
      if (o.isMesh) {
        if (o.geometry) o.geometry.dispose();
        const mats = Array.isArray(o.material) ? o.material : [o.material];
        mats.filter(Boolean).forEach(m => {
          Object.keys(m).forEach(k => {
            const val = m[k];
            if (val && val.isTexture) val.dispose();
          });
          if (m.dispose) m.dispose();
        });
      }
      if (o.dispose) o.dispose();
    });
    maskObject = null;
  }
}

function loadMask(type) {
  clearMask();
  currentMask = type;
  currentConfig = maskConfigs[type] || {baseScale: 1.6, zOffset: -0.55, yOffset: 0, xOffset: 0};
  const url = maskModels[type];

  gltfLoader.load(url, (gltf) => {
    maskObject = gltf.scene;
    // Mirror to align with non-flipped video (we keep video unmirrored)
    maskObject.rotation.y = Math.PI;
    maskObject.scale.setScalar(currentConfig.baseScale);
    maskObject.position.set(currentConfig.xOffset, currentConfig.yOffset, currentConfig.zOffset);
    scene.add(maskObject);
    maskEl.textContent = `MASK: ${type.toUpperCase()}`;
    log(`MASK LOADED: ${type.toUpperCase()}`);
  }, undefined, (err) => {
    const geo = new THREE.DodecahedronGeometry(0.15, 1);
    const mat = new THREE.MeshStandardMaterial({color:0x00ff88, metalness:0.4, roughness:0.6});
    maskObject = new THREE.Mesh(geo, mat);
    maskObject.rotation.y = Math.PI;
    maskObject.scale.setScalar(currentConfig.baseScale);
    maskObject.position.set(currentConfig.xOffset, currentConfig.yOffset, currentConfig.zOffset);
    scene.add(maskObject);
    maskEl.textContent = `MASK: ${type.toUpperCase()} (FALLBACK)`;
    log(`FALLBACK MASK: ${type.toUpperCase()} — ${err?.message || 'load error'}`);
  });
}

// Smoothing state
const smooth = {
  pos: new THREE.Vector3(),
  rot: new THREE.Euler(),
  scale: 1.0,
  alphaPos: 0.35,
  alphaRot: 0.35,
  alphaScale: 0.25
};

function lerpAngle(a, b, t) {
  let diff = b - a;
  while (diff > Math.PI) diff -= Math.PI * 2;
  while (diff < -Math.PI) diff += Math.PI * 2;
  return a + diff * t;
}

function clamp(v, min, max) { return Math.max(min, Math.min(max, v)); }

function updateMask(landmarks) {
  if (!maskObject || !landmarks || landmarks.length < 468) return;

  // Use landmarks as-is (video not mirrored)
  const lm = landmarks;

  // MediaPipe indices: left eye outer (33), right eye outer (263), nose tip (1)
  const le = lm[33], re = lm[263], nose = lm[1];

  const eyeDist = Math.hypot(re.x - le.x, re.y - le.y);
  const centerX = (le.x + re.x) / 2;
  const centerY = (le.y + re.y) / 2;

  // Compute target scale based on inter-eye distance
  const trackedScale = clamp(THREE.MathUtils.lerp(1.4, 3.2, eyeDist * 10), 1.2, 3.5);

  // Map landmark center to normalized view (-1..1 approx) tuned to framing
  const targetX = (centerX - 0.5) * 2.2 + (currentConfig.xOffset || 0);
  const targetY = -(centerY - 0.5) * 2.2 + (currentConfig.yOffset || 0) + 0.06;
  const targetZ = currentConfig.zOffset || -0.52;

  // Yaw from horizontal eye vector; pitch from nose vs center; roll from eye slope
  const yaw = (re.x - le.x) * 4.0;
  const pitchDeg = (centerY - nose.y) * 34;
  const roll = Math.atan2(le.y - re.y, re.x - le.x);

  // Smooth position
  smooth.pos.x = THREE.MathUtils.lerp(smooth.pos.x, targetX, smooth.alphaPos);
  smooth.pos.y = THREE.MathUtils.lerp(smooth.pos.y, targetY, smooth.alphaPos);
  smooth.pos.z = THREE.MathUtils.lerp(smooth.pos.z, targetZ, smooth.alphaPos);

  // Smooth scale
  const targetScale = trackedScale * currentConfig.baseScale;
  smooth.scale = THREE.MathUtils.lerp(smooth.scale || targetScale, targetScale, smooth.alphaScale);

  // Smooth rotation
  const targetPitch = THREE.MathUtils.degToRad(clamp(pitchDeg, -25, 25));
  const targetYaw = Math.PI + clamp(yaw, -0.5, 0.5);
  const targetRoll = clamp(roll, -0.6, 0.6);

  smooth.rot.x = lerpAngle(smooth.rot.x || targetPitch, targetPitch, smooth.alphaRot);
  smooth.rot.y = lerpAngle(smooth.rot.y || targetYaw,   targetYaw,   smooth.alphaRot);
  smooth.rot.z = lerpAngle(smooth.rot.z || targetRoll,  targetRoll,  smooth.alphaRot);

  // Apply to mask
  maskObject.position.copy(smooth.pos);
  maskObject.scale.setScalar(smooth.scale);
  maskObject.rotation.set(smooth.rot.x, smooth.rot.y, smooth.rot.z);
}

async function startAR() {
  if (running) return;
  log('REQUESTING CAMERA PERMISSION...');
  try {
    const stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: 'user', width: {ideal: 1280}, height: {ideal: 720} },
      audio: false
    });
    video.srcObject = stream;
    await video.play();
    log('CAMERA PERMISSION GRANTED');

    const vision = await FilesetResolver.forVisionTasks(
      'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.14/wasm'
    );

    const isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent);
    faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
      baseOptions: {
        modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task',
        delegate: isIOS ? 'CPU' : 'GPU'
      },
      runningMode: 'VIDEO',
      numFaces: 1,
      outputFaceBlendshapes: false
    });

    log('AR CORE ACTIVE – FACE TRACKING INITIALIZED');
    trackEl.textContent = 'TRACKING: LOCKED';
    trackEl.classList.add('locked');

    running = true;
    loop();
  } catch (e) {
    log('CAMERA PERMISSION DENIED OR ERROR: ' + e.message);
    trackEl.textContent = 'TRACKING: OFF';
    trackEl.classList.remove('locked');
  }
}

function loop() {
  if (!running) return;
  if (faceLandmarker && video.readyState >= 2) {
    const results = faceLandmarker.detectForVideo(video, Date.now());
    if (results.faceLandmarks && results.faceLandmarks[0]) {
      updateMask(results.faceLandmarks[0]);
      renderer.render(scene, camera);
    }
  }
  rafId = requestAnimationFrame(loop);
}

document.getElementById('start').onclick = startAR;
document.getElementById('mask-select').onchange = e => loadMask(e.target.value);

document.getElementById('export').onclick = () => {
  if (!maskObject) return log('NO MASK LOADED');
  const data = {
    mask: currentMask,
    position: { x: maskObject.position.x, y: maskObject.position.y, z: maskObject.position.z },
    rotation: { x: maskObject.rotation.x, y: maskObject.rotation.y, z: maskObject.rotation.z },
    scale: maskObject.scale.x
  };
  const blob = new Blob([JSON.stringify(data, null, 2)], {type: 'application/json'});
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url;
  a.download = `channel8_${currentMask}_fit.json`;
  a.click();
  log(`EXPORTED: ${currentMask.toUpperCase()} FIT JSON`);
};

document.addEventListener('visibilitychange', () => {
  if (document.hidden) {
    running = false;
    if (rafId) cancelAnimationFrame(rafId);
  } else {
    if (faceLandmarker && video.srcObject) {
      running = true; loop();
    }
  }
});

initThree();
loadMask('oni');
log('CHANNEL 8 AR READY – PRESS SYNC TO DEPLOY');
</script>
</body>
</html>
